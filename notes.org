* Inbox
** [2024-02-05 Mo 19:51] DFA State self Propergation

Unordered State List
Apply Regexes sequencially
** [2024-01-07 So 13:31] Define Weak Tokens

Weak tokens are ignored if they'd cause an error, but can still be consumed by if needed

[[file:~/projects/MLCC/src/parser.rs]]
** [2024-01-05 Fr 16:14] Lexer Process

1. Collect all Tokens
2. Generate Lexer from all tokens
   - DFA Table :: State(resolve?, next(char)->State)
   - Output Map :: Output->Token[]
   - s/r conflicts :: Error Type
3. NFA Collapse using the Lexer Map function (might increase branching)
4. Generated Lexer function takes the State map as argument to filter invalid outputs

[[file:~/projects/MLCC/src/lexer.rs::2. Read Quirks (usize) -> try to resolve Quirks]]
** [2024-01-03 Mi 04:02] Seperate LExer redundent?

*** Points for Integrated Lexer
| Pro                | Contra                 |
|--------------------+------------------------|
| Elegant            | Large Parse Table      |
| Generalized Regex  | Regex Runtime Overhead |
| Single Parse Table | Compilation Speed      |
| Maintainability    |                        |
| Innovative         |                        |

**** Fixes
- Parse Table Size ::
  The Parse Table Size could be accommodated for with Parse Table Compression.

*** Points for Seperate Lexer
| Pro                       | Contra                  |
|---------------------------+-------------------------|
| Smaller Parse Table       | Redundancy              |
| Performance benefit       | Many Extra Tables       |
| Traditional Regex support | cache Inefficiency      |
|                           | Clunky interoperability |

*** Conclusion
I think i want to try the Integrated Lexer. It feels more Elegant and less Hacky than providing a map from state to Lexers,
Implementing "Regexy" Features into the Parse Grammar would integrate nicely with auto struct generation

[[file:~/projects/MLCC/regex.g]]
